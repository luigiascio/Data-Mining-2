{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b991de24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import seaborn as sns\n",
    "import random as rn\n",
    "import copy as copy\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6aa3cde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('imbd_cleaned.csv')\n",
    "\n",
    "X = df.select_dtypes(include=['number'])\n",
    "X = X.drop(['averageRating'], axis = 1)\n",
    "X = X.values\n",
    "y = np.array(df['rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582e826b",
   "metadata": {},
   "source": [
    "## Data Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "52be6fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abba53cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=100, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "02098a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a2773456",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e113ef",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73ab4189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf5aa873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcfed38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.36725127837086213\n",
      "F1-score [0.         0.         0.00516796 0.00383509 0.02125399 0.27648202\n",
      " 0.32591205 0.52907553 0.09114359 0.03255485]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lavigi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Lavigi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      (0, 1]       0.00      0.00      0.00        26\n",
      "      (1, 2]       0.00      0.00      0.00       141\n",
      "      (2, 3]       0.03      0.00      0.01       353\n",
      "      (3, 4]       0.12      0.00      0.00      1027\n",
      "      (4, 5]       0.29      0.01      0.02      2719\n",
      "      (5, 6]       0.29      0.27      0.28      6372\n",
      "      (6, 7]       0.32      0.33      0.33     11643\n",
      "      (7, 8]       0.42      0.72      0.53     14463\n",
      "      (8, 9]       0.24      0.06      0.09      6563\n",
      "     (9, 10]       0.17      0.02      0.03      1281\n",
      "\n",
      "    accuracy                           0.37     44588\n",
      "   macro avg       0.19      0.14      0.13     44588\n",
      "weighted avg       0.32      0.37      0.31     44588\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lavigi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "clf = HistGradientBoostingClassifier(learning_rate=1.0, max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e043b93",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "https://xgboost.readthedocs.io/en/stable/python/python_intro.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1818771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Using cached xgboost-3.0.0-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\lavigi\\programmi\\lib\\site-packages (from xgboost) (1.24.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\lavigi\\programmi\\lib\\site-packages (from xgboost) (1.11.1)\n",
      "Using cached xgboost-3.0.0-py3-none-win_amd64.whl (150.0 MB)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\Lavigi\\programmi\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\Lavigi\\programmi\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\Lavigi\\programmi\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98595d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train convertito: [6 7 7 ... 6 8 6]\n",
      "y_test convertito: [8 7 6 ... 5 4 5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convert_interval_to_numeric(interval):\n",
    "    # Rimuovi le parentesi e dividi per la virgola\n",
    "    lower, upper = interval[1:-1].split(', ')\n",
    "    # Converti in float e calcola il punto medio\n",
    "    return int(lower)\n",
    "\n",
    "# Applica la conversione a y_train e y_test\n",
    "y_train_numeric = np.array([convert_interval_to_numeric(interval) for interval in y_train])\n",
    "y_test_numeric = np.array([convert_interval_to_numeric(interval) for interval in y_test])\n",
    "\n",
    "print(\"y_train convertito:\", y_train_numeric)\n",
    "print(\"y_test convertito:\", y_test_numeric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3fbb7551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6fed2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lavigi\\programmi\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [10:27:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.5133443975957657\n",
      "F1-score [0.37837838 0.27       0.22692308 0.2609216  0.36440849 0.41377634\n",
      " 0.4602241  0.6467887  0.47157191 0.54801325]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.27      0.38        26\n",
      "           1       0.46      0.19      0.27       141\n",
      "           2       0.35      0.17      0.23       353\n",
      "           3       0.34      0.21      0.26      1027\n",
      "           4       0.40      0.33      0.36      2719\n",
      "           5       0.43      0.40      0.41      6372\n",
      "           6       0.46      0.46      0.46     11643\n",
      "           7       0.59      0.71      0.65     14463\n",
      "           8       0.52      0.43      0.47      6563\n",
      "           9       0.58      0.52      0.55      1281\n",
      "\n",
      "    accuracy                           0.51     44588\n",
      "   macro avg       0.48      0.37      0.40     44588\n",
      "weighted avg       0.50      0.51      0.51     44588\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, roc_curve, precision_recall_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definisci il modello\n",
    "clf = XGBClassifier(objective='binary:logistic', tree_method='exact', use_label_encoder=True, random_state=42)\n",
    "\n",
    "# Definisci la griglia di parametri\n",
    "param_dist = {\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'reg_lambda': [0, 1, 10],\n",
    "    'reg_alpha': [0, 0.1, 1]\n",
    "}\n",
    "\n",
    "# Imposta la grid search con early stopping\n",
    "fit_params = {\n",
    "    'early_stopping_rounds': 10,\n",
    "    'eval_metric': 'logloss',\n",
    "    'eval_set': [(X_test, y_test_numeric)],\n",
    "    'verbose': False\n",
    "}\n",
    "\n",
    "n_iter = 30\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=clf, param_distributions=param_dist, scoring='accuracy', \n",
    "                                   cv=5, verbose=2, n_jobs=-1, n_iter=n_iter)\n",
    "\n",
    "# Esegui la grid search con early stopping\n",
    "random_search.fit(X_train, y_train_numeric, **fit_params)\n",
    "\n",
    "# Stampa i migliori parametri\n",
    "print(\"Migliori parametri trovati:\", random_search.best_params_)\n",
    "print(\"Miglior punteggio:\", random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede4fd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold cross validation\n",
    "kfold = StratifiedKFold(n_splits=5)\n",
    "results = cross_val_score(random_search.best_estimator_, X_train, y_train_numeric, cv=kfold)\n",
    "print(\"Risultati della K-fold cross validation:\", results)\n",
    "print(\"Media dei risultati della K-fold cross validation:\", results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b99bc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcola il numero medio di epoch del miglior modello\n",
    "best_model = random_search.best_estimator_\n",
    "best_model.fit(X_train, y_train_numeric)\n",
    "evals_result = best_model.evals_result()\n",
    "epochs = len(evals_result['validation_0']['logloss'])\n",
    "print(\"Numero medio di epoch del miglior modello:\", epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f4247c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcola la ROC curve e la Precision-Recall curve\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, _ = roc_curve(y_test_numeric, y_pred_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_test_numeric, y_pred_proba)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot Precision-Recall curve\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, label='Precision-Recall curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
